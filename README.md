# Image Captioning With Gradio
This project demonstrates how to create a web application that generates captions for images using the BLIP-2 model and the Gradio library. Follow the steps below to set up and run the application.

## Table of Contents
* Introduction
* Setup Instructions
* Usage
* Code Explaination
* Contribution
* License
* Contact

## Introduction
In this project, I will explain the steps I used to create a web application that generates captions for images using the BLIP-2 model and the Gradio library. The application leverages a pretrained model from Salesforce for generating descriptive captions.

## Setup Instructions
### Prerequisites
Ensure you have the following 
* Python 3.x
* Pip (Pythhon package Installer)
### Installation
1. Clone the repository
2. Install the require libraries:
   - pip install gradio transformers pillow
   - pip install tensorflow
   - pip install pytorch

## Create the Python Script
create a new Python file name 'image_captioning_app.py' and add the codes

## Running the Application
To run the application, navigate to the directory conntaining 'image_captioning_app.py' and execute the following command:
<img width="410" alt="Screenshot 2024-07-25 183015" src="https://github.com/user-attachments/assets/8f61043e-ae3c-4a29-81b4-5794b877e768">
This will start a local web server. Open the provided URL in yout web browser to use the image captioning app.

## Usage
1. Open your browser and navigate to the local server URL provided in the terminal
2. Upload an image using the web interface
3. Wait for the model to process the image and generate a caption
4. The generated caption will be displayed on the web page.

## Code Explaination
